{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaitanzx/fish_speech/blob/main/fish_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "VjYy0F2gZIPR",
        "outputId": "26274fc7-34a6-4605-d73a-3df301846743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pygit2==1.15.1 in /usr/local/lib/python3.11/dist-packages (1.15.1)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "/content\n",
            "Cloning into 'fish_speech'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
            "remote: Total 239 (delta 39), reused 138 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (239/239), 28.91 MiB | 19.67 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/fish_speech\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.3.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.3.0%2Bcu118-cp311-cp311-linux_x86_64.whl (839.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.7/839.7 MB\u001b[0m \u001b[31m958.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.3.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nccl-cu11==2.20.5 (from torch==2.3.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.3.0+cu118 torchaudio-2.3.0+cu118 torchvision-0.18.0+cu118 triton-2.3.0\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.3.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.3.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.47.1)\n",
            "Collecting datasets (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning (from -r requirements.txt (line 5))\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core (from -r requirements.txt (line 6))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.17.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.10.2.post1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (13.9.4)\n",
            "Collecting gradio (from -r requirements.txt (line 12))\n",
            "  Downloading gradio-5.13.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.19.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.70.0)\n",
            "Collecting kui (from -r requirements.txt (line 15))\n",
            "  Downloading kui-1.8.1-py3-none-any.whl.metadata (984 bytes)\n",
            "Collecting zibai-server (from -r requirements.txt (line 16))\n",
            "  Downloading zibai_server-0.13.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting loguru (from -r requirements.txt (line 17))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting loralib (from -r requirements.txt (line 18))\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils (from -r requirements.txt (line 20))\n",
            "  Downloading pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting vector_quantize_pytorch==1.14.24 (from -r requirements.txt (line 21))\n",
            "  Downloading vector_quantize_pytorch-1.14.24-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting samplerate==0.1.0 (from -r requirements.txt (line 22))\n",
            "  Downloading samplerate-0.1.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting resampy (from -r requirements.txt (line 23))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting spaces (from -r requirements.txt (line 24))\n",
            "  Downloading spaces-0.32.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->-r requirements.txt (line 25))\n",
            "  Downloading einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opencc (from -r requirements.txt (line 26))\n",
            "  Downloading OpenCC-1.1.9-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting faster-whisper (from -r requirements.txt (line 27))\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ormsgpack (from -r requirements.txt (line 28))\n",
            "  Downloading ormsgpack-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg (from -r requirements.txt (line 29))\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (0.13.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (5.5.1)\n",
            "Collecting funasr (from -r requirements.txt (line 32))\n",
            "  Downloading funasr-1.2.3-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting silero-vad (from -r requirements.txt (line 33))\n",
            "  Downloading silero_vad-5.1.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting tiktoken (from -r requirements.txt (line 34))\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (8.7.0.84)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (11.8.86)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from samplerate==0.1.0->-r requirements.txt (line 22)) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from samplerate==0.1.0->-r requirements.txt (line 22)) (1.26.4)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->-r requirements.txt (line 25)) (2.4.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (2.2.2)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch==2.3.0->-r requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 4)) (3.11.11)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning->-r requirements.txt (line 5))\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning->-r requirements.txt (line 5))\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pytorch-lightning (from lightning->-r requirements.txt (line 5))\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core->-r requirements.txt (line 6))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core->-r requirements.txt (line 6))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 11)) (2.18.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (0.28.1)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (2.10.6)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 12)) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio->-r requirements.txt (line 12)) (14.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 13)) (1.3.4)\n",
            "Collecting baize>=0.20.0 (from kui->-r requirements.txt (line 15))\n",
            "  Downloading baize-0.22.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: h11>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from zibai-server->-r requirements.txt (line 16)) (0.14.0)\n",
            "Collecting python-dotenv>=0.20.0 (from pyrootutils->-r requirements.txt (line 20))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper->-r requirements.txt (line 27))\n",
            "  Downloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper->-r requirements.txt (line 27))\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster-whisper->-r requirements.txt (line 27))\n",
            "  Downloading av-14.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting jamo (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 32)) (0.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 32)) (0.42.1)\n",
            "Collecting pytorch-wpe (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr->-r requirements.txt (line 32)) (0.8.1)\n",
            "Collecting oss2 (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardX (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting modelscope (from funasr->-r requirements.txt (line 32))\n",
            "  Downloading modelscope-1.22.3-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->samplerate==0.1.0->-r requirements.txt (line 22)) (2.22)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13)) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 12)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 12)) (1.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 11)) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 10)) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 27))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 27)) (25.1.21)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 12)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 12)) (1.5.4)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr->-r requirements.txt (line 32))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr->-r requirements.txt (line 32))\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr->-r requirements.txt (line 32))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr->-r requirements.txt (line 32))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr->-r requirements.txt (line 32))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr->-r requirements.txt (line 32))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr->-r requirements.txt (line 32)) (43.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 13)) (5.0.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 27))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading vector_quantize_pytorch-1.14.24-py3-none-any.whl (36 kB)\n",
            "Downloading samplerate-0.1.0-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.13.2-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kui-1.8.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zibai_server-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaces-0.32.0-py3-none-any.whl (29 kB)\n",
            "Downloading OpenCC-1.1.9-cp311-cp311-manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.6/220.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funasr-1.2.3-py3-none-any.whl (701 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.4/701.4 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading silero_vad-5.1.2-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading av-14.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.5/39.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading baize-0.22.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (733 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.9/733.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading modelscope-1.22.3-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, ffmpeg, jaconv, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=0ca1195d727ef68e1e8f2ab149a0768ff535ee5c0be53da67dcfc550eb164768\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=b053fc7506b21ac23794f54b8da00b5b7c7a236e76e5bf530c44b69b40001dfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18229 sha256=f5f83fe47f157c994edad4e04b540e7f1961cb3e53cd99921f271355aa63617a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/71/95fb322fe9047ed7e61b007c47cbf03d23ecb77dd03665f151\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.1-py3-none-any.whl size=123943 sha256=d24289bde06a35f9878557ae4d3f02d123cad081e8dd61dbcd394e1d14f737b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/27/a3/50e7db0dd68810d9d4e383a547b88b4a5b1eaae58e63c1d64a\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535316 sha256=0aacbb7b5590ea90ac32d23ff37ec596a53b828c2f57dc0a1bacba4d6294cb50\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/9a/95/60f111d2a488c5f7f7ed2a96ce407ea57ec7393ddfdec8c956\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31655 sha256=94db1701746c76ec8b7290598855ee106572b63bc6ae3fcfd6aa3c07bc90c50c\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
            "Successfully built antlr4-python3-runtime ffmpeg jaconv oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: pydub, opencc, jamo, jaconv, ffmpeg, crcmod, antlr4-python3-runtime, zibai-server, xxhash, uvicorn, torch-complex, tomlkit, tensorboardX, semantic-version, ruff, pytorch-wpe, python-multipart, python-dotenv, pycryptodome, ormsgpack, omegaconf, markupsafe, loralib, loguru, lightning-utilities, kaldiio, jmespath, humanfriendly, fsspec, ffmpy, dill, ctranslate2, baize, av, aiofiles, tiktoken, starlette, samplerate, resampy, pyrootutils, multiprocess, modelscope, hydra-core, einx, coloredlogs, safehttpx, pynndescent, onnxruntime, kui, gradio-client, fastapi, aliyun-python-sdk-core, vector_quantize_pytorch, umap-learn, torchmetrics, gradio, faster-whisper, datasets, aliyun-python-sdk-kms, spaces, silero-vad, pytorch-lightning, oss2, lightning, funasr\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 antlr4-python3-runtime-4.9.3 av-14.1.0 baize-0.22.2 coloredlogs-15.0.1 crcmod-1.7 ctranslate2-4.5.0 datasets-3.2.0 dill-0.3.8 einx-0.2.2 fastapi-0.115.7 faster-whisper-1.1.1 ffmpeg-1.4 ffmpy-0.5.0 fsspec-2024.9.0 funasr-1.2.3 gradio-5.13.2 gradio-client-1.6.0 humanfriendly-10.0 hydra-core-1.3.2 jaconv-0.4.0 jamo-0.4.1 jmespath-0.10.0 kaldiio-2.18.0 kui-1.8.1 lightning-2.5.0.post0 lightning-utilities-0.11.9 loguru-0.7.3 loralib-0.1.2 markupsafe-2.1.5 modelscope-1.22.3 multiprocess-0.70.16 omegaconf-2.3.0 onnxruntime-1.20.1 opencc-1.1.9 ormsgpack-1.7.0 oss2-2.19.1 pycryptodome-3.21.0 pydub-0.25.1 pynndescent-0.5.13 pyrootutils-1.0.4 python-dotenv-1.0.1 python-multipart-0.0.20 pytorch-lightning-2.5.0.post0 pytorch-wpe-0.0.1 resampy-0.4.3 ruff-0.9.3 safehttpx-0.1.6 samplerate-0.1.0 semantic-version-2.10.0 silero-vad-5.1.2 spaces-0.32.0 starlette-0.45.3 tensorboardX-2.6.2.2 tiktoken-0.8.0 tomlkit-0.13.2 torch-complex-0.4.4 torchmetrics-1.6.1 umap-learn-0.5.7 uvicorn-0.34.0 vector_quantize_pytorch-1.14.24 xxhash-3.5.0 zibai-server-0.13.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "660b813f69ac4561934c79bd3c3cd9a6",
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 7 files:   0% 0/7 [00:00<?, ?it/s]\n",
            "tokenizer.tiktoken:   0% 0.00/1.70M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "special_tokens.json: 100% 31.0k/31.0k [00:00<00:00, 4.30MB/s]\n",
            "\n",
            "\n",
            "config.json: 100% 697/697 [00:00<00:00, 4.72MB/s]\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   0% 0.00/189M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   0% 0.00/1.28G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "README.md: 100% 1.68k/1.68k [00:00<00:00, 11.9MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 11.6MB/s]\n",
            "Fetching 7 files:  14% 1/7 [00:00<00:01,  3.27it/s]\n",
            "tokenizer.tiktoken: 100% 1.70M/1.70M [00:00<00:00, 13.5MB/s]\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   6% 10.5M/189M [00:00<00:04, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   1% 10.5M/1.28G [00:00<00:32, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  11% 21.0M/189M [00:00<00:04, 41.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   2% 21.0M/1.28G [00:00<00:30, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  17% 31.5M/189M [00:00<00:03, 41.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   2% 31.5M/1.28G [00:00<00:29, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  22% 41.9M/189M [00:00<00:03, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   3% 41.9M/1.28G [00:01<00:29, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  28% 52.4M/189M [00:01<00:03, 42.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   4% 52.4M/1.28G [00:01<00:28, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  33% 62.9M/189M [00:01<00:02, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   5% 62.9M/1.28G [00:01<00:28, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  39% 73.4M/189M [00:01<00:02, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   6% 73.4M/1.28G [00:01<00:28, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   7% 83.9M/1.28G [00:01<00:28, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  44% 83.9M/189M [00:02<00:02, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   7% 94.4M/1.28G [00:02<00:27, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  50% 94.4M/189M [00:02<00:02, 38.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   8% 105M/1.28G [00:02<00:27, 42.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  56% 105M/189M [00:02<00:02, 39.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   9% 115M/1.28G [00:02<00:27, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  61% 115M/189M [00:02<00:01, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  10% 126M/1.28G [00:02<00:27, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  67% 126M/189M [00:03<00:01, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  11% 136M/1.28G [00:03<00:26, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  72% 136M/189M [00:03<00:01, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  12% 147M/1.28G [00:03<00:26, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  78% 147M/189M [00:03<00:01, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  12% 157M/1.28G [00:03<00:26, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  83% 157M/189M [00:03<00:00, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  13% 168M/1.28G [00:03<00:26, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  89% 168M/189M [00:04<00:00, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  14% 178M/1.28G [00:04<00:26, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  95% 178M/189M [00:04<00:00, 41.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  15% 189M/1.28G [00:04<00:25, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth: 100% 189M/189M [00:04<00:00, 40.8MB/s]\n",
            "Fetching 7 files:  57% 4/7 [00:04<00:03,  1.29s/it]\n",
            "\n",
            "\n",
            "model.pth:  16% 199M/1.28G [00:04<00:25, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  16% 210M/1.28G [00:04<00:25, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  17% 220M/1.28G [00:05<00:24, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  18% 231M/1.28G [00:05<00:24, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  19% 241M/1.28G [00:05<00:24, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  20% 252M/1.28G [00:05<00:24, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  21% 262M/1.28G [00:06<00:24, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  21% 273M/1.28G [00:06<00:24, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  22% 283M/1.28G [00:06<00:23, 41.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  23% 294M/1.28G [00:06<00:23, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  24% 304M/1.28G [00:07<00:23, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  25% 315M/1.28G [00:07<00:22, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  25% 325M/1.28G [00:07<00:22, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  26% 336M/1.28G [00:07<00:22, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  27% 346M/1.28G [00:08<00:21, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  28% 357M/1.28G [00:08<00:21, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  29% 367M/1.28G [00:08<00:21, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  30% 377M/1.28G [00:08<00:21, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  30% 388M/1.28G [00:09<00:20, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  31% 398M/1.28G [00:09<00:20, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  32% 409M/1.28G [00:09<00:20, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  33% 419M/1.28G [00:09<00:20, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  34% 430M/1.28G [00:10<00:19, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  35% 440M/1.28G [00:10<00:19, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  35% 451M/1.28G [00:10<00:19, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  36% 461M/1.28G [00:10<00:19, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  37% 472M/1.28G [00:11<00:16, 48.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  38% 482M/1.28G [00:11<00:15, 50.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  39% 493M/1.28G [00:11<00:16, 47.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  39% 503M/1.28G [00:11<00:16, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  40% 514M/1.28G [00:12<00:17, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  41% 524M/1.28G [00:12<00:17, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  42% 535M/1.28G [00:12<00:17, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  43% 545M/1.28G [00:12<00:17, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  44% 556M/1.28G [00:13<00:16, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  44% 566M/1.28G [00:13<00:16, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  45% 577M/1.28G [00:13<00:16, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  46% 587M/1.28G [00:13<00:16, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  47% 598M/1.28G [00:13<00:16, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  48% 608M/1.28G [00:14<00:15, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  48% 619M/1.28G [00:14<00:15, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  49% 629M/1.28G [00:14<00:15, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  50% 640M/1.28G [00:14<00:14, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  51% 650M/1.28G [00:15<00:14, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  52% 661M/1.28G [00:15<00:16, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  53% 671M/1.28G [00:15<00:13, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  53% 682M/1.28G [00:15<00:13, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  54% 692M/1.28G [00:16<00:13, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  55% 703M/1.28G [00:16<00:13, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  56% 713M/1.28G [00:16<00:13, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  57% 724M/1.28G [00:16<00:13, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  58% 734M/1.28G [00:17<00:12, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  58% 744M/1.28G [00:17<00:12, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  59% 755M/1.28G [00:17<00:12, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  60% 765M/1.28G [00:17<00:12, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  61% 776M/1.28G [00:18<00:11, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  62% 786M/1.28G [00:18<00:11, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  62% 797M/1.28G [00:18<00:11, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  63% 807M/1.28G [00:18<00:11, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  64% 818M/1.28G [00:19<00:10, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  65% 828M/1.28G [00:19<00:10, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  66% 839M/1.28G [00:19<00:10, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  67% 849M/1.28G [00:19<00:10, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  67% 860M/1.28G [00:20<00:09, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  68% 870M/1.28G [00:20<00:09, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  69% 881M/1.28G [00:20<00:09, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  70% 891M/1.28G [00:20<00:09, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  71% 902M/1.28G [00:21<00:08, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  71% 912M/1.28G [00:21<00:08, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  72% 923M/1.28G [00:21<00:08, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  73% 933M/1.28G [00:21<00:08, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  74% 944M/1.28G [00:22<00:07, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  75% 954M/1.28G [00:22<00:07, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  76% 965M/1.28G [00:22<00:07, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  76% 975M/1.28G [00:22<00:07, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  77% 986M/1.28G [00:23<00:06, 41.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  78% 996M/1.28G [00:23<00:06, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  79% 1.01G/1.28G [00:23<00:06, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  80% 1.02G/1.28G [00:23<00:06, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  81% 1.03G/1.28G [00:24<00:05, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  81% 1.04G/1.28G [00:24<00:05, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  82% 1.05G/1.28G [00:24<00:05, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  83% 1.06G/1.28G [00:24<00:05, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  84% 1.07G/1.28G [00:25<00:04, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  85% 1.08G/1.28G [00:25<00:04, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  85% 1.09G/1.28G [00:25<00:04, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  86% 1.10G/1.28G [00:25<00:04, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  87% 1.11G/1.28G [00:26<00:03, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  88% 1.12G/1.28G [00:26<00:03, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  89% 1.13G/1.28G [00:26<00:03, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  90% 1.14G/1.28G [00:26<00:03, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  90% 1.15G/1.28G [00:27<00:02, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  91% 1.16G/1.28G [00:27<00:02, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  92% 1.17G/1.28G [00:27<00:02, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  93% 1.18G/1.28G [00:27<00:02, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  94% 1.20G/1.28G [00:28<00:01, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  95% 1.21G/1.28G [00:28<00:01, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  95% 1.22G/1.28G [00:28<00:01, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  96% 1.23G/1.28G [00:28<00:01, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  97% 1.24G/1.28G [00:29<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  98% 1.25G/1.28G [00:29<00:00, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  99% 1.26G/1.28G [00:29<00:00, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  99% 1.27G/1.28G [00:29<00:00, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth: 100% 1.28G/1.28G [00:30<00:00, 42.3MB/s]\n",
            "Fetching 7 files: 100% 7/7 [00:30<00:00,  4.35s/it]\n",
            "All checkpoints downloaded\n",
            "/content/fish_speech/_main.py:31: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "\u001b[32m2025-01-29 02:57:00.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m446\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:13.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m682\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:13.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m688\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:13.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m696\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:13.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m453\u001b[0m - \u001b[1mLlama model loaded, loading VQ-GAN model...\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:14.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.vqgan.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:14.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m461\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:14.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:14.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 1/1\u001b[0m\n",
            "  0% 21/8168 [00:01<10:49, 12.55it/s]\n",
            "\u001b[32m2025-01-29 02:57:17.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 2.72 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:17.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 23 tokens in 2.72 seconds, 8.45 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:17.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.39 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:17.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 1.75 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:17.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 22])\u001b[0m\n",
            "\u001b[32m2025-01-29 02:57:18.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://8b324368348453c10c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            "Но последнее сражение состоится не в будущем.\n",
            "Оно состоится здесь, в наше время, сегодня ночью.\n",
            "Арнольд Шварценеггер, Майкл Биен,\n",
            "Линда Хамильтон, Лэнс Хенриксон\n",
            "и Пол Уинфилд в роли Лейтенанта Трекслера,\n",
            "а также другие актеры.\n",
            "Монтаж Марка Голдблетта.\n",
            "Оператор Адам Гринберг.\n",
            "Композитор Брэд Фиттл.\n",
            "Авторы сценария Джеймс Камерон и Гейл Н. Хёрд.\n",
            "Продюсер Гейл Н. Хёрд.\n",
            "Режиссер Джеймс Камерон.\n",
            "Киборг Убийца. None  1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 02:58:44.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\n",
            "Но последнее сражение состоится не в будущем.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Оно состоится здесь, в наше время, сегодня ночью.\n",
            "Арнольд Шварценеггер, Майкл Биен,\n",
            "Линда Хамильтон,\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Лэнс Хенриксон\n",
            "и Пол Уинфилд в роли Лейтенанта Трекслера,\n",
            "а также другие актеры.\n",
            "Монтаж Марка Голдблетта.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Оператор Адам Гринберг.\n",
            "Композитор Брэд Фиттл.\n",
            "Авторы сценария Джеймс Камерон и Гейл Н. Хёрд.\n",
            "Продюсер Гейл Н.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Хёрд.\n",
            "Режиссер Джеймс Камерон.\n",
            "Киборг Убийца.\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:44.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/6 of sample 1/1\u001b[0m\n",
            " 16% 165/1023 [00:13<01:12, 11.88it/s]\n",
            "\u001b[32m2025-01-29 02:58:58.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 14.18 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:58.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 167 tokens in 14.18 seconds, 11.78 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:58.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.52 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:58.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 1.79 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:58.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 02:58:58.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 166])\u001b[0m\n",
            "  9% 97/1023 [00:08<01:16, 12.05it/s]\n",
            "\u001b[32m2025-01-29 02:59:06.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 99 tokens in 8.43 seconds, 11.75 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:06.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.49 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:06.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 2.29 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:06.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 3/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:06.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 98])\u001b[0m\n",
            " 14% 147/1023 [00:12<01:14, 11.69it/s]\n",
            "\u001b[32m2025-01-29 02:59:20.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 149 tokens in 13.14 seconds, 11.34 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:20.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.24 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:20.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 2.29 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:20.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 4/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:20.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 148])\u001b[0m\n",
            " 15% 155/1023 [00:13<01:13, 11.77it/s]\n",
            "\u001b[32m2025-01-29 02:59:33.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 157 tokens in 13.95 seconds, 11.26 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:33.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.18 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:33.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 2.62 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:33.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 5/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:33.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 156])\u001b[0m\n",
            " 13% 136/1023 [00:11<01:16, 11.59it/s]\n",
            "\u001b[32m2025-01-29 02:59:46.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 138 tokens in 12.71 seconds, 10.85 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:46.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.92 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:46.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.07 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:46.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 6/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:46.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 137])\u001b[0m\n",
            "  7% 75/1023 [00:06<01:26, 10.97it/s]\n",
            "\u001b[32m2025-01-29 02:59:54.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 77 tokens in 7.94 seconds, 9.70 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:54.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.19 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:54.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 02:59:54.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 76])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            "Но последнее сражение состоится не в будущем.\n",
            "Оно состоится здесь, в наше время, сегодня ночью.\n",
            "Арнольд Шварценеггер, Майкл Биен,\n",
            "Линда Хамильтон, Лэнс Хенриксон\n",
            "и Пол Уинфилд в роли Лейтенанта Трекслера,\n",
            "а также другие актеры.\n",
            "Монтаж Марка Голдблетта.\n",
            "Оператор Адам Гринберг.\n",
            "Композитор Брэд Фиттл.\n",
            "Авторы сценария Джеймс Камерон и Гейл Н. Хёрд.\n",
            "Продюсер Гейл Н. Хёрд.\n",
            "Режиссер Джеймс Камерон.\n",
            "Киборг Убийца. None  1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:00:20.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\n",
            "Но последнее сражение состоится не в будущем.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Оно состоится здесь, в наше время, сегодня ночью.\n",
            "Арнольд Шварценеггер, Майкл Биен,\n",
            "Линда Хамильтон,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Лэнс Хенриксон\n",
            "и Пол Уинфилд в роли Лейтенанта Трекслера,\n",
            "а также другие актеры.\n",
            "Монтаж Марка Голдблетта.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Оператор Адам Гринберг.\n",
            "Композитор Брэд Фиттл.\n",
            "Авторы сценария Джеймс Камерон и Гейл Н. Хёрд.\n",
            "Продюсер Гейл Н.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Хёрд.\n",
            "Режиссер Джеймс Камерон.\n",
            "Киборг Убийца.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/6 of sample 1/1\u001b[0m\n",
            " 20% 201/1023 [00:16<01:09, 11.88it/s]\n",
            "\u001b[32m2025-01-29 03:00:37.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.18 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:37.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 203 tokens in 17.18 seconds, 11.81 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:37.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.54 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:37.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:37.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:37.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 202])\u001b[0m\n",
            " 10% 101/1023 [00:09<01:23, 11.03it/s]\n",
            "\u001b[32m2025-01-29 03:00:47.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 103 tokens in 9.81 seconds, 10.50 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:47.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.70 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:47.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:47.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 3/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:00:47.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 102])\u001b[0m\n",
            " 15% 151/1023 [00:13<01:15, 11.54it/s]\n",
            "\u001b[32m2025-01-29 03:01:01.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 153 tokens in 13.73 seconds, 11.15 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:01.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.11 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:01.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:01.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 4/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:01.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 152])\u001b[0m\n",
            " 16% 167/1023 [00:14<01:13, 11.71it/s]\n",
            "\u001b[32m2025-01-29 03:01:16.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 169 tokens in 15.14 seconds, 11.16 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:16.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.12 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:16.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:16.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 5/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:16.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 168])\u001b[0m\n",
            " 18% 189/1023 [00:16<01:11, 11.65it/s]\n",
            "\u001b[32m2025-01-29 03:01:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 191 tokens in 17.32 seconds, 11.03 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.03 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:33.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 3.61 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:33.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 6/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:33.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 190])\u001b[0m\n",
            "  9% 88/1023 [00:08<01:27, 10.72it/s]\n",
            "\u001b[32m2025-01-29 03:01:43.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 90 tokens in 9.51 seconds, 9.46 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:43.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.04 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:43.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:01:43.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 89])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            "Но последнее сражение состоится не в будущем.\n",
            "Оно состоится здесь, в наше время, сегодня ночью.\n",
            "Арнольд Шварценеггер, Майкл Биен,\n",
            "Линда Хамильтон, Лэнс Хенриксон\n",
            "и Пол Уинфилд в роли Лейтенанта Трекслера,\n",
            "а также другие актеры.\n",
            "Монтаж Марка Голдблетта.\n",
            "Оператор Адам Гринберг.\n",
            "Композитор Брэд Фиттл.\n",
            "Авторы сценария Джеймс Камерон и Гейл Н. Хёрд.\n",
            "Продюсер Гейл Н. Хёрд.\n",
            "Режиссер Джеймс Камерон.\n",
            "Киборг Убийца. None  1024 32 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:02:41.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: 2029 год.\n",
            "И\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: восстали машины\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: из пепла\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ядерного огня.\n",
            "И\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: пошла война на\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: уничтожение\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: человечества.\n",
            "И\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: шла она\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: десятилетия.\n",
            "Но\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: последнее\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: сражение\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: состоится не в\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: будущем.\n",
            "Оно\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: состоится здесь,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: в наше время,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: сегодня ночью.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Арнольд\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Шварценеггер,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Майкл Биен,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Линда Хамильтон,\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Лэнс Хенриксон\n",
            "и\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Пол Уинфилд в\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: роли Лейтенанта\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Трекслера,\n",
            "а\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: также другие\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: актеры.\n",
            "Монтаж\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Марка Голдблетта.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Оператор Адам\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Гринберг.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Композитор Брэд\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Фиттл.\n",
            "Авторы\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: сценария Джеймс\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Камерон и Гейл Н.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Хёрд.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Продюсер Гейл Н.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Хёрд.\n",
            "Режиссер\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Джеймс Камерон.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Киборг Убийца.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:41.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/39 of sample 1/1\u001b[0m\n",
            "  2% 21/1023 [00:02<01:54,  8.77it/s]\n",
            "\u001b[32m2025-01-29 03:02:44.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 2.65 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 23 tokens in 2.65 seconds, 8.69 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.54 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:44.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:44.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:44.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 22])\u001b[0m\n",
            "  4% 41/1023 [00:03<01:24, 11.55it/s]\n",
            "\u001b[32m2025-01-29 03:02:47.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 43 tokens in 3.85 seconds, 11.17 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:47.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.13 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:47.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:47.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 3/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:47.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 42])\u001b[0m\n",
            "  3% 27/1023 [00:02<01:24, 11.76it/s]\n",
            "\u001b[32m2025-01-29 03:02:50.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 29 tokens in 2.54 seconds, 11.40 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:50.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.27 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:50.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:50.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 4/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:50.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 28])\u001b[0m\n",
            "  2% 20/1023 [00:01<01:24, 11.91it/s]\n",
            "\u001b[32m2025-01-29 03:02:52.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 22 tokens in 1.97 seconds, 11.16 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:52.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.12 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:52.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:52.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 5/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:52.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 21])\u001b[0m\n",
            "  4% 43/1023 [00:03<01:28, 11.07it/s]\n",
            "\u001b[32m2025-01-29 03:02:56.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 45 tokens in 4.20 seconds, 10.71 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:56.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.83 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:56.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:56.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 6/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:02:56.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 44])\u001b[0m\n",
            "  4% 36/1023 [00:03<01:37, 10.14it/s]\n",
            "\u001b[32m2025-01-29 03:03:00.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 38 tokens in 3.92 seconds, 9.71 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:00.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.19 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:00.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:00.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 7/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:00.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 37])\u001b[0m\n",
            "  2% 24/1023 [00:01<01:21, 12.30it/s]\n",
            "\u001b[32m2025-01-29 03:03:02.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 26 tokens in 2.33 seconds, 11.15 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:02.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.12 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:02.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:02.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 8/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:02.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 25])\u001b[0m\n",
            "  4% 37/1023 [00:02<01:19, 12.35it/s]\n",
            "\u001b[32m2025-01-29 03:03:06.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 39 tokens in 3.43 seconds, 11.37 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:06.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.26 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:06.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:06.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 9/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:06.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 38])\u001b[0m\n",
            "  2% 16/1023 [00:01<01:23, 12.04it/s]\n",
            "\u001b[32m2025-01-29 03:03:08.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 18 tokens in 1.79 seconds, 10.03 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:08.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.40 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:08.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:08.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 10/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:08.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 17])\u001b[0m\n",
            "  3% 34/1023 [00:03<01:47,  9.19it/s]\n",
            "\u001b[32m2025-01-29 03:03:12.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 36 tokens in 4.18 seconds, 8.60 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:12.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.49 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:12.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:12.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 11/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:12.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 35])\u001b[0m\n",
            "  2% 19/1023 [00:01<01:25, 11.76it/s]\n",
            "\u001b[32m2025-01-29 03:03:14.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 21 tokens in 2.19 seconds, 9.59 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:14.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.12 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:14.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:14.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 12/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 20])\u001b[0m\n",
            "  2% 18/1023 [00:01<01:24, 11.84it/s]\n",
            "\u001b[32m2025-01-29 03:03:16.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 20 tokens in 2.09 seconds, 9.58 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:16.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.11 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:16.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:16.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 13/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:16.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 19])\u001b[0m\n",
            "  3% 33/1023 [00:02<01:21, 12.07it/s]\n",
            "\u001b[32m2025-01-29 03:03:19.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 35 tokens in 3.32 seconds, 10.55 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:19.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.73 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:19.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:19.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 14/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:19.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 34])\u001b[0m\n",
            "  3% 31/1023 [00:02<01:20, 12.25it/s]\n",
            "\u001b[32m2025-01-29 03:03:23.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 33 tokens in 3.15 seconds, 10.47 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:23.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.68 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:23.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:23.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 15/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:23.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 32])\u001b[0m\n",
            "  3% 35/1023 [00:03<01:47,  9.20it/s]\n",
            "\u001b[32m2025-01-29 03:03:27.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 37 tokens in 4.49 seconds, 8.25 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:27.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.26 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:27.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:27.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 16/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:27.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 36])\u001b[0m\n",
            "  2% 22/1023 [00:01<01:24, 11.84it/s]\n",
            "\u001b[32m2025-01-29 03:03:30.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 24 tokens in 2.59 seconds, 9.28 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.92 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 17/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:30.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 23])\u001b[0m\n",
            "  3% 33/1023 [00:02<01:19, 12.38it/s]\n",
            "\u001b[32m2025-01-29 03:03:33.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 35 tokens in 3.41 seconds, 10.25 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:33.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.54 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:33.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:33.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 18/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:33.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 34])\u001b[0m\n",
            "  2% 16/1023 [00:01<01:25, 11.80it/s]\n",
            "\u001b[32m2025-01-29 03:03:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 18 tokens in 2.12 seconds, 8.50 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:35.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.42 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:35.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:35.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 19/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:35.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 17])\u001b[0m\n",
            "  2% 21/1023 [00:02<01:43,  9.68it/s]\n",
            "\u001b[32m2025-01-29 03:03:38.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 23 tokens in 2.97 seconds, 7.76 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:38.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.95 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:38.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:38.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 20/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:38.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 22])\u001b[0m\n",
            "  2% 20/1023 [00:02<01:50,  9.08it/s]\n",
            "\u001b[32m2025-01-29 03:03:41.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 22 tokens in 3.07 seconds, 7.16 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:41.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.57 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:41.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:41.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 21/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:41.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 21])\u001b[0m\n",
            "  2% 23/1023 [00:01<01:23, 11.95it/s]\n",
            "\u001b[32m2025-01-29 03:03:44.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 25 tokens in 2.77 seconds, 9.01 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:44.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.75 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:44.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:44.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 22/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:44.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 24])\u001b[0m\n",
            "  4% 36/1023 [00:02<01:21, 12.15it/s]\n",
            "\u001b[32m2025-01-29 03:03:48.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 38 tokens in 3.86 seconds, 9.84 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:48.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.28 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:48.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:48.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 23/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:48.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 37])\u001b[0m\n",
            "  2% 24/1023 [00:01<01:23, 12.01it/s]\n",
            "\u001b[32m2025-01-29 03:03:51.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 26 tokens in 2.95 seconds, 8.82 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:51.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.63 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:51.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:51.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 24/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:51.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 25])\u001b[0m\n",
            "  2% 25/1023 [00:02<01:58,  8.45it/s]\n",
            "\u001b[32m2025-01-29 03:03:55.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 27 tokens in 3.98 seconds, 6.78 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:55.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.32 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:55.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:55.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 25/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:55.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 26])\u001b[0m\n",
            "  3% 29/1023 [00:02<01:22, 12.06it/s]\n",
            "\u001b[32m2025-01-29 03:03:58.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 31 tokens in 3.43 seconds, 9.04 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:58.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.77 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:58.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.21 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:58.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 26/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:03:58.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 30])\u001b[0m\n",
            "  2% 22/1023 [00:01<01:22, 12.07it/s]\n",
            "\u001b[32m2025-01-29 03:04:01.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 24 tokens in 2.91 seconds, 8.24 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:01.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.26 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:01.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 4.81 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:01.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 27/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:01.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 23])\u001b[0m\n",
            "  3% 34/1023 [00:02<01:21, 12.19it/s]\n",
            "\u001b[32m2025-01-29 03:04:05.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 36 tokens in 3.88 seconds, 9.28 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:05.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.92 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:05.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 5.43 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:05.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 28/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:05.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 35])\u001b[0m\n",
            "  3% 26/1023 [00:03<01:56,  8.55it/s]\n",
            "\u001b[32m2025-01-29 03:04:09.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 28 tokens in 4.21 seconds, 6.64 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:09.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.24 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:09.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 6.08 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:09.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 29/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:09.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 27])\u001b[0m\n",
            "  2% 24/1023 [00:01<01:22, 12.17it/s]\n",
            "\u001b[32m2025-01-29 03:04:12.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 26 tokens in 3.13 seconds, 8.30 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:12.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.30 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:12.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 6.75 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:12.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 30/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:12.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 25])\u001b[0m\n",
            "  2% 16/1023 [00:01<01:23, 12.02it/s]\n",
            "\u001b[32m2025-01-29 03:04:15.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 18 tokens in 2.52 seconds, 7.13 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:15.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.55 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:15.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 7.44 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:15.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 31/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:15.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 17])\u001b[0m\n",
            "  3% 26/1023 [00:02<01:21, 12.16it/s]\n",
            "\u001b[32m2025-01-29 03:04:18.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 28 tokens in 3.37 seconds, 8.31 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:18.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.30 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:18.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 8.15 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:18.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 32/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:18.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 27])\u001b[0m\n",
            "  3% 32/1023 [00:03<01:53,  8.76it/s]\n",
            "\u001b[32m2025-01-29 03:04:23.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 34 tokens in 4.91 seconds, 6.92 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:23.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.42 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:23.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 8.88 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:23.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 33/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:23.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 33])\u001b[0m\n",
            "  3% 26/1023 [00:02<01:21, 12.22it/s]\n",
            "\u001b[32m2025-01-29 03:04:27.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 28 tokens in 3.44 seconds, 8.15 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:27.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.20 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:27.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 9.64 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:27.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 34/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:27.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 27])\u001b[0m\n",
            "  3% 29/1023 [00:02<01:22, 12.09it/s]\n",
            "\u001b[32m2025-01-29 03:04:30.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 31 tokens in 3.73 seconds, 8.30 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:30.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.29 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:30.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 10.43 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:30.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 35/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:30.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 30])\u001b[0m\n",
            "  1% 12/1023 [00:01<01:29, 11.34it/s]\n",
            "\u001b[32m2025-01-29 03:04:33.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 14 tokens in 2.42 seconds, 5.77 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:33.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 3.68 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:33.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 11.24 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:33.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 36/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:33.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 13])\u001b[0m\n",
            "  3% 29/1023 [00:03<01:53,  8.73it/s]\n",
            "\u001b[32m2025-01-29 03:04:38.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 31 tokens in 4.75 seconds, 6.52 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:38.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.16 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:38.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 12.06 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:38.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 37/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:38.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 30])\u001b[0m\n",
            "  3% 34/1023 [00:02<01:20, 12.34it/s]\n",
            "\u001b[32m2025-01-29 03:04:42.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 36 tokens in 4.19 seconds, 8.58 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:42.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.48 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:42.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 12.91 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:42.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 38/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:42.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 35])\u001b[0m\n",
            "  2% 23/1023 [00:01<01:22, 12.12it/s]\n",
            "\u001b[32m2025-01-29 03:04:45.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 25 tokens in 3.38 seconds, 7.40 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:45.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.72 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:45.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 13.80 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:45.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 39/39 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:45.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 24])\u001b[0m\n",
            "  2% 25/1023 [00:02<01:47,  9.32it/s]\n",
            "\u001b[32m2025-01-29 03:04:49.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 27 tokens in 4.18 seconds, 6.45 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:49.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.12 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:49.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:04:49.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 26])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " None  1024 200 0.7 1.5 0.7 0\n",
            "\u001b[32m2025-01-29 03:05:40.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:40.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:40.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 18% 183/1023 [00:15<01:11, 11.69it/s]\n",
            "\u001b[32m2025-01-29 03:05:56.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 15.93 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:56.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 185 tokens in 15.93 seconds, 11.61 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.41 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:56.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 184])\u001b[0m\n",
            "  4% 39/1023 [00:03<01:18, 12.49it/s]\n",
            "\u001b[32m2025-01-29 03:05:59.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 41 tokens in 3.76 seconds, 10.91 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:59.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.96 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:59.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:05:59.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 40])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " None  1024 200 0.7 1.2 0.9 0\n",
            "\u001b[32m2025-01-29 03:06:25.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:25.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:25.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 18% 180/1023 [00:15<01:12, 11.65it/s]\n",
            "\u001b[32m2025-01-29 03:06:40.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 15.72 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:40.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 182 tokens in 15.72 seconds, 11.57 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:40.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.38 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:40.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:40.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:40.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 181])\u001b[0m\n",
            "  3% 35/1023 [00:03<01:50,  8.91it/s]\n",
            "\u001b[32m2025-01-29 03:06:45.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 37 tokens in 4.58 seconds, 8.07 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:45.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.15 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:45.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:06:45.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 36])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " None  1024 200 0.7 1.2 0.7 36647663563\n",
            "\u001b[32m2025-01-29 03:07:18.750\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minference\u001b[0m:\u001b[36m135\u001b[0m - \u001b[33m\u001b[1mset seed: 36647663563\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:18.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:18.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:18.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 18% 181/1023 [00:15<01:12, 11.59it/s]\n",
            "\u001b[32m2025-01-29 03:07:34.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 15.93 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:34.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 183 tokens in 15.93 seconds, 11.49 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:34.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.33 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:34.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:34.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:34.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 182])\u001b[0m\n",
            "  3% 35/1023 [00:03<01:32, 10.73it/s]\n",
            "\u001b[32m2025-01-29 03:07:38.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 37 tokens in 3.89 seconds, 9.51 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:38.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.07 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:38.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 14.70 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:07:38.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 36])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/d45f6acb82f291631b43d7b4ef6667fb3c9ebbe665b9fdcee98d739175dbe250/RU_Male_Denis_Kolesnikov.mp3 ﻿Друзья, всем большой и пламенный! Меня зовут Денис Колесников, также известный вам как Кураж Бомбей.\n",
            "И это очередной отчётный выпуск сериального трындеца за октябрь.\n",
            "А точнее я расскажу вам о том, какие сериалы вы могли пропустить в ушедшем октябре.\n",
            "Начинаем сразу с тех, что вернулись на экраны в нашей постоянной рубрике \"Не прошло и года\".\n",
            "В начале октября на американские телеканалы вернулись сериалы, которые очень многие действительно давно ждали.\n",
            "В частности, это сериал \"Спецназ\" - \"SWAT Team\". На CBS он вернулся уже с третьим сезоном.\n",
            "Там же на CBS стартовал шестой сезон \"Государственного секретаря\".\n",
            "Теа Леони в главной роли.\n",
            "\"Чёрный список\" вернулся на NBC, уже с седьмым сезоном.\n",
            "Ну а \"Мистер Робот\" с Рами Малеком и финальным сезоном вернулся на телеканал \"USA\".\n",
            "Там же 16 октября стартовал новый сезон сериальной версии \"Судной ночи\".\n",
            "Если вы смотрели фильмы этой серии, да и сам первый сезон, знайте, что вот уже подоспел второй.\n",
            "\"Супергерл\", не желая отставать от соперницы в лице Бэтвумен, про которую мы недавно рассказывали, прилетела уже с пятым сезоном на CW.\n",
            "Туда же вернулся \"Флэш\" с теперь уже шестым сезоном, \"Ривердейл\" и \"Стрела\" аж с восьмым сезоном.\n",
            "Стриминги в этом месяце тоже не отставали.\n",
            "Например, на Amazon Prime теперь можно посмотреть третий сезон \"Голиафа\".\n",
            "В общем, туда вернулся мрачнейший второй сезон сериала-антологии \"Into the Dark\" или \"Навстречу тьме\".\n",
            "А еще там же стартовал второй сезон \"Касл Рока\", который очень-очень долго готовился, но стартовал, надо сказать, вполне себе даже неплохо.\n",
            "На Netflix со вторыми сезонами вернулись \"Ненасытная\" и \"Метод Комински\".\n",
            "Про \"Метод Комински\" я, наверное, пожалуй, сделаю отдельный выпуск и расскажу о том, какой он классный.\n",
            "Первый был классный, и второй оказался не хуже.\n",
            "Ну и, наконец, на HBO официально вернулся с финальным сезоном сериал \"Кремниевая долина\". 1024 200 0.7 1.2 0.7 36647663563\n",
            "\u001b[32m2025-01-29 03:08:17.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 116.43 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:18.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 2507])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:18.384\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minference\u001b[0m:\u001b[36m135\u001b[0m - \u001b[33m\u001b[1mset seed: 36647663563\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:18.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:18.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:18.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 17% 177/1023 [00:14<01:11, 11.83it/s]\n",
            "\u001b[32m2025-01-29 03:08:36.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.70 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:36.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 179 tokens in 17.70 seconds, 10.11 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:36.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.45 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:36.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:36.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:36.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 178])\u001b[0m\n",
            "  3% 33/1023 [00:03<01:33, 10.54it/s]\n",
            "\u001b[32m2025-01-29 03:08:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 35 tokens in 6.56 seconds, 5.34 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 3.41 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:08:42.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 34])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/ef69a75c97b347522ce0b44a5f70982b824c646361d3f09756bda0bfd144f133/RU_Male_Tinkoff.mp3 ﻿Ни ху я!\n",
            "Вот просто ни ху я!\n",
            "Это было не просто смело, это было пиздец как смело.\n",
            "Я говорю, Миш, мне похую.\n",
            "Я так чувствую. Какое-то величие, какая-то хуйня, мне вообще они не интересны.\n",
            "Ну это пиздец какой-то просто, ну сколько можно?\n",
            "Сомнительно, но окей.\n",
            "Круто! Да это ж круто!\n",
            "Я уважаю, что они делают.\n",
            "Но как бы я не понимаю.\n",
            "Я реально прихерел.\n",
            "Это конечно печально.\n",
            "Это печально.\n",
            "Ну что это за пиздец такой?\n",
            "Ну...\n",
            "Блядь, я заплакал!\n",
            "Конечно, мы все виноваты в этом пиздеце.\n",
            "Ну побо... Вот какая разница?\n",
            "Ну вот какая разница?\n",
            "It's ok. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:09:28.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 46.21 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:29.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 995])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:29.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:29.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:29.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 18% 188/1023 [00:16<01:11, 11.73it/s]\n",
            "\u001b[32m2025-01-29 03:09:46.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.18 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:46.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 190 tokens in 17.18 seconds, 11.06 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:46.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.05 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:46.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:46.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:46.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 189])\u001b[0m\n",
            "  3% 32/1023 [00:02<01:21, 12.09it/s]\n",
            "\u001b[32m2025-01-29 03:09:50.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 34 tokens in 4.29 seconds, 7.93 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:50.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 5.06 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:50.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:09:50.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 33])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/c751071e0fd53e3bbc8798429c4e507c42f4ae80f3460a138d07593ba30dcf74/RU_Male_Deadpool.mp3 ﻿Прости, опоздал.\n",
            "Я снимал детей инвалидов с высокого дерева и…\n",
            "Ну ладно.\n",
            "Я собирал весь глютен в мире и запускал его в космос,\n",
            "чтобы он не отравлял нам жизнь.\n",
            "Диарея?\n",
            "Нужно раздеться, чтобы проверить, но…\n",
            "Похоже, дело в ней.\n",
            "Что такая грязная дыра забыла в этой девушке?\n",
            "Малыш?\n",
            "Малыш!\n",
            "Хорошо не дошло до ножа для масла.\n",
            "Ты, значит, жрица спермы?\n",
            "Детство трудное.\n",
            "А мой еще до зачатия.\n",
            "Как-то я весь день рождения просидел в запертом шкафу,\n",
            "который был мне еще и…\n",
            "Будь я стокилограммовой какахой по имени Фрэнсис, куда бы я заныкался?\n",
            "Он там точно висел еще до нас.\n",
            "Вот мне еще гепатита не хватало.\n",
            "О, еще и скользко.\n",
            "Девушка, стол нам вытрите?\n",
            "Нам бы столик протереть.\n",
            "Силенок не многовато для леди?\n",
            "Ты что, транс?\n",
            "А спичка – это у тебя оральная фиксация?\n",
            "Или ты фанатка Сталоне?\n",
            "А вы пришли уборку в номере сделать?\n",
            "Нет, я с вас худею.\n",
            "Вы эту явку светили в Тиндере?\n",
            "Грайндере?\n",
            "В комиксах ты повыше будешь. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:10:16.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 78.89 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:16.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 1699])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:16.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:17.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:17.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 18% 186/1023 [00:15<01:11, 11.64it/s]\n",
            "\u001b[32m2025-01-29 03:10:34.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.83 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:34.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 188 tokens in 17.83 seconds, 10.54 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:34.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.73 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:34.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:34.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:34.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 187])\u001b[0m\n",
            "  4% 41/1023 [00:03<01:18, 12.52it/s]\n",
            "\u001b[32m2025-01-29 03:10:40.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 43 tokens in 5.64 seconds, 7.62 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:40.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.86 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:40.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:10:40.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 42])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/566ccdea0773b2ebe496758b9c95f08fd8ec7e9c3f47aabb4efc3410b399455b/RU_Male_Craster_YouTube.mp3 ﻿А здрасти, с вами Даня Крастер и лаборатория БНБ.\n",
            "И сегодня мы поговорим непосредственно про наше ремесло, про создание вещей.\n",
            "Мы живем в такое время, когда у нас куча всего существует в э цифровом виде.\n",
            "Куча моделей, всяких чертежей.\n",
            "И если вы захотите привнести одну из этих штук в свой проект,\n",
            "непосредственно отобразить это на физическом носителе в виде материала,\n",
            "вы можете вот на этом чуваке перенести 3D-модель на барельеф,\n",
            "или возможно сделать какую-то модельку с переворотом, или на поворотной оси,\n",
            "или же не использовать ЧПУ фрезера, а перейти сразу на готовую печать цельной какой-то модельки\n",
            "на одном из вот этих чуваков.\n",
            "Вам все равно понадобится 3D-модель этой штуки в каком-то виде.\n",
            "И именно о методах ее получения без проектирования и художественной лепки мы сегодня и поговорим.\n",
            "Многие слышали про 3D-печать и про 3D-моделирование,\n",
            "и наверняка у каждого есть знакомый задрот в этой теме.\n",
            "По этому самый простой способ достать необходимую 3D-модельку - это обратиться к такому корешу.\n",
            "Но, максимальной удачей считается найти готовую среди миллионов всевозможных моделек\n",
            "в общедоступных 3D-библиотеках.\n",
            "А еще круче - уметь делать их самому.\n",
            "3D-моделирование - если раз в пять лет тебе ударит в голову распечатать какую-нибудь фигнюшку домой или в машину,\n",
            "или, может, тебе захотелось оцифровать свою любимую ласточку и поставить ее маленькую копию на торпеду.\n",
            "Не будешь же, ты ее с нуля рисовать и пробовать 50 разных профессиональных программ.\n",
            "Именно для таких случаев существует 3D-сканирование.\n",
            "Эта технология сэкономит и время, и нервы.\n",
            "Но все познается в сравнении.\n",
            "Мы сегодня собрали разные методы, чтобы вы поняли разницу и, возможно, даже чем-то воспользовались. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:11:01.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 99.55 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:01.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 2144])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:01.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:01.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:01.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 17% 176/1023 [00:15<01:12, 11.72it/s]\n",
            "\u001b[32m2025-01-29 03:11:18.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.35 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:18.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 178 tokens in 17.35 seconds, 10.26 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:18.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.54 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:18.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:18.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:18.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 177])\u001b[0m\n",
            "  4% 41/1023 [00:04<01:47,  9.17it/s]\n",
            "\u001b[32m2025-01-29 03:11:26.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 43 tokens in 7.39 seconds, 5.82 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:26.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 3.71 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:26.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:26.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 42])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/d629226438d00a9ccacb05db8885e99d14277d3baae7b5e7e4fe545a4b22e073/RU_Male_Buhmin_AudioBook.mp3 ﻿Наш главный редактор Мамонт, в миру Семен Ильич, конечно, но за глаза его никто, кроме как Мамонтом, не называет, ибо он велик ростом, могуч телом, зело волосат и громкоголос. Всегда умеет удивить сотрудников.\n",
            "То матерно загнет такую тираду, что даже корреспонденты, бывающие в военных частях и в горячих точках, поразятся тонкости ее плетения и многообразию выражений. То с прибывшим в редакцию корейцем по-корейски пообщается. То на корпоративе нижний брейк станцует.\n",
            "И всякий раз на широко открытые глаза издательской братии, а нас пойди удиви, уж вроде все видали, что только можно, всегда говорит: \"А вы чего удивились? Я еще в лохматом году, и так далее, служил на подлодке, сбивал в Корее фантомы, снимался в фильме «Курьер» в финальной сцене, и так далее\". И не важно, что между этими событиями может лежать временная пропасть. Если Мамонт сказал, то так оно и есть на самом деле.\n",
            "Вот и сегодня звонит мне по внутреннему и говорит:\n",
            "— Никифоров, ты? Трезвый?\n",
            "\"Вот ведь зараза какая! Всего-то один раз пришел бухой с одной подзатянувшейся вечеринки, причем было это уже как год с лишним назад. Но он об этом событии не забывает и при всяком удобном случае колет им мне глаза\".\n",
            "— Зайди-ка ко мне.\n",
            "— Партия сказала. Комсомол ответил — есть.\n",
            "Если шеф зовет, значит, это кому-нибудь нужно, и не важно, что этот кто-нибудь не я. В том смысле, что мне такие визиты к руководству нафиг не нужны.\n",
            "Захожу к нему, а он сидит весь такой набыченный, прям как хан Мамай перед Куликовской битвой, и глаз у него такой недобрый. Не иначе как бубну мне собрался выбивать.\n",
            "— Ты, Никифоров, совсем мух не ловишь в последнее время.\n",
            "Все мои ожидания оправдались. Сегодня именно я стану дежурной жертвой нашего гениального. Он же упырь такой, уснуть не сможет, пока живой крови не напьется. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:11:55.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 125.07 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:55.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 2694])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:55.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:55.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:11:55.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 20% 200/1023 [00:17<01:12, 11.39it/s]\n",
            "\u001b[32m2025-01-29 03:12:16.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 20.39 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:16.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 202 tokens in 20.39 seconds, 9.91 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:16.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.32 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:16.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 201])\u001b[0m\n",
            "  4% 45/1023 [00:03<01:18, 12.46it/s]\n",
            "\u001b[32m2025-01-29 03:12:23.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 47 tokens in 7.27 seconds, 6.47 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:23.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.13 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:23.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:12:23.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 46])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/54964db77ef50ad4c3d4a5e0b051d88ec5b70ad8d66617d3f6973778dbec333f/RU_Female_Kropina_YouTube.mp3 ﻿Но что если я вам скажу, что вы можете стать, который\n",
            "об этом даже не подозревает?\n",
            "Да не просто о человеком, который прикончил члена\n",
            "семьи Кимов, который сейчас правит Северной Кореей,\n",
            "если вы вдруг забыли.\n",
            "И все это под видом пранка на ютубе.\n",
            "Сегодня мы поговорим о том, как две молодые девушки\n",
            "умудрились в одной из самых пугающих политических\n",
            "династий.\n",
            "И сделали они это с помощью детского масла.\n",
            "Я постараюсь сдержать шутки про пьедиди, но ничего\n",
            "не обещаю.\n",
            "Присаживайтесь поудобнее, заваривайте себе вкусного\n",
            "чая или кофе и давайте приступим.\n",
            "И подписывайтесь еще обязательно на мой телеграм-канал, потому\n",
            "что ютуб у нас снова замедляют.\n",
            "Я не знаю, что делать, но если что-то и буду делать,\n",
            "то обновы будут.\n",
            "Отлично знают, какую цену приходится платить за славу.\n",
            "В 2017 году за желание прославиться на ютубе они чуть не поплатились\n",
            "собственной жизнью.\n",
            "Но кто эти девушки и почему когда-то их называли одними\n",
            "из самых известных киллеров в истории?\n",
            "О жизни Доан известно очень мало.\n",
            "В 2017 году ей было 28 лет.\n",
            "Ее аккаунты в социальных сетях демонстрируют знакомый\n",
            "нам всем образ жизни - путешествия, фото с едой и так далее.\n",
            "Но далеко не все так радужно, как нам кажется на первый\n",
            "взгляд.\n",
            "Доан выросла на рисовой ферме в одноэтажном кирпичном\n",
            "домике в деревне на севере Вьетнама.\n",
            "Этот район известен разве что большим количеством\n",
            "церквей и ничем больше.\n",
            "Отец Доан - раненый ветеран Вьетнамской войны, а мать\n",
            "была тяжело больной и скончалась в 2015 году.\n",
            "Все они жили небогато и работали на рынке. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:13:00.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 99.00 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:00.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 2132])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:00.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:00.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:00.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 27% 280/1023 [00:24<01:04, 11.48it/s]\n",
            "\u001b[32m2025-01-29 03:13:27.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 26.66 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:27.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 282 tokens in 26.66 seconds, 10.58 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:27.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 6.75 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:27.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:27.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:27.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 281])\u001b[0m\n",
            "  5% 49/1023 [00:05<01:40,  9.67it/s]\n",
            "\u001b[32m2025-01-29 03:13:35.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 51 tokens in 8.23 seconds, 6.19 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:35.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 3.95 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:35.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:13:35.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 50])\u001b[0m\n",
            "call inference wrapper ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\n",
            "И шла она десятилетия.\n",
            " /tmp/gradio/ee2e7b8d69dfccccbae04b3ed704b672c8f3dae22c6b92578772a9cf3e478476/Nice English Ref.wav At the Sahara restaurant in Dearborn, Michigan, for Arabic language TV news channels are beaming in images of the war in Gaza, and the aftermath of the recent pager and radio devices explosions in Lebanon, The smell of Caramum infused coffee and Shawarma and falafel and hum of friends catching up, stand in stark contrast to the images on the television screens, Dearborn is the first Arab majority city in the U. and it has served as a key center for the uncommitted movement that is opposed to the Biden administration. Poy toward the Middle East, because they are in Michigan, a key Midwestern swing state that Joe Biden won by fewer than three points in 2020 Dearborn voters, like those who frequentequent the Sahara restaurant, could decide Kamala Harris's political future. Sam Hamoutd, whose family has run the Sahara restaurant in Dearborn for the past 30 years, said that taxes and inflation have negatively affected his business, but it's not what is motivating his vote. He is currently an undecided voter. 1024 200 0.7 1.2 0.7 0\n",
            "\u001b[32m2025-01-29 03:14:16.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m169\u001b[0m - \u001b[1mLoaded audio with 59.57 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:16.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 1283])\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:17.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: ﻿Лос-Анджелес, 2029 год.\n",
            "И восстали машины из пепла ядерного огня.\n",
            "И пошла война на уничтожение человечества.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:17.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: И шла она десятилетия.\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:17.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/2 of sample 1/1\u001b[0m\n",
            " 19% 192/1023 [00:16<01:10, 11.84it/s]\n",
            "\u001b[32m2025-01-29 03:14:34.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m852\u001b[0m - \u001b[1mCompilation time: 17.59 seconds\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:34.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 194 tokens in 17.59 seconds, 11.03 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:34.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 7.03 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:34.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:34.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 2/2 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:34.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 193])\u001b[0m\n",
            "  4% 42/1023 [00:04<01:39,  9.81it/s]\n",
            "\u001b[32m2025-01-29 03:14:40.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 44 tokens in 6.21 seconds, 7.08 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:40.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 4.52 GB/s\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:40.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 15.55 GB\u001b[0m\n",
            "\u001b[32m2025-01-29 03:14:40.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 43])\u001b[0m\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2870, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fish_speech/_main.py\", line 486, in <module>\n",
            "    app.queue(api_open=True).launch(show_error=True, show_api=True, inbrowser=True, share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2775, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2874, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8b324368348453c10c.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# fish_speech\n",
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/shaitanzx/fish_speech.git\n",
        "\n",
        "%cd /content/fish_speech\n",
        "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -r requirements.txt\n",
        "!python main.py --share True\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}